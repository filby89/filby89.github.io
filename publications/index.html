<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Panagiotis P. Filntisis</title> <meta name="author" content="Panagiotis P. Filntisis"/> <meta name="description" content=""/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://filby89.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://filby89.github.io/">Panagiotis P. Filntisis</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/pfilntisis_cv.pdf">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div id="filntisis2022visual" class="col-sm"> <div class="title">Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, George Retsinas, Foivos Paraperas-Papantoniou, Athanasios Katsamanis, Anastasios Roussos,  and Petros Maragos </div> <div class="periodical"> <em>arXiv preprint arXiv:2207.11094</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2207.11094" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/spectre" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="https://filby89.github.io/spectre" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2022visual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Retsinas, George and Paraperas-Papantoniou, Foivos and Katsamanis, Athanasios and Roussos, Anastasios and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2207.11094}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="paraperas2022ned" class="col-sm"> <div class="title">Neural Emotion Director: Speech-preserving semantic control of facial expressions in "in-the-wild" videos</div> <div class="author"> Foivos Paraperas Papantoniou,  <em>Panagiotis P. Filntisis</em>, Petros Maragos,  and Anastasios Roussos </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Oral - Best Paper Finalist)</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/Paraperas_NED-SpeechPreservingSemanticControlFacialExpressions_CVPR2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/foivospar/NED" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="https://foivospar.github.io/NED/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">paraperas2022ned</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Emotion Director: Speech-preserving semantic control of facial expressions in "in-the-wild" videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paraperas Papantoniou, Foivos and Filntisis, Panagiotis P. and Maragos, Petros and Roussos, Anastasios}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Oral - Best Paper Finalist)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="efthymiou2022childbot" class="col-sm"> <div class="title">Childbot: Multi-robot perception and interaction with children</div> <div class="author"> Niki Efthymiou,  <em>Panagiotis P. Filntisis</em>, Petros Koutras, Antigoni Tsiami, Jack Hadfield, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>Robotics and Autonomous Systems</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/2022_EfthymiouEtAl_ChildBot-MultiRobotPerception-InteractionChildren_RAS.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">efthymiou2022childbot</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Childbot: Multi-robot perception and interaction with children}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Efthymiou, Niki and Filntisis, Panagiotis P. and Koutras, Petros and Tsiami, Antigoni and Hadfield, Jack and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Robotics and Autonomous Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{150}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{103975}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{North-Holland}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="garoufis2022towards" class="col-sm"> <div class="title">Towards unsupervised subject-independent speech-based relapse detection in patients with psychosis using variational autoencoders</div> <div class="author"> Christos Garoufis, Athanasia Zlatintsi,  <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Emmanouil Kalisperakis, Vassiliki Garyfalli, Marina Lazaridi, Nikolaos Smyrnis,  and Petros Maragos </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">garoufis2022towards</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garoufis, Christos and Zlatintsi, Athanasia and Filntisis, Panagiotis P. and Efthymiou, Niki and Kalisperakis, Emmanouil and Garyfalli, Vassiliki and Lazaridi, Marina and Smyrnis, Nikolaos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="panagiotou2022" class="col-sm"> <div class="title">A comparative study of autoencoder architectures for mental health analysis using wearable sensors data</div> <div class="author"> Maria Panagiotou, Athanasia Zlatintsi,  <em>Panagiotis P. Filntisis</em>, Argyris Roumeliotis, Niki Efthymiou,  and Petros Maragos </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">panagiotou2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Panagiotou, Maria and Zlatintsi, Athanasia and Filntisis, Panagiotis P. and Roumeliotis, Argyris and Efthymiou, Niki and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="tze2022cartoon" class="col-sm"> <div class="title">Cartoonized Anonymization of Sign Language Videos</div> <div class="author"> Christina Ourania Tze,  <em>Panagiotis P. Filntisis</em>, Anastasios Roussos,  and Petros Maragos </div> <div class="periodical"> <em>In Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tze2022cartoon</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cartoonized Anonymization of Sign Language Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tze, Christina Ourania and Filntisis, Panagiotis P. and Roussos, Anastasios and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="retsinas2022attr" class="col-sm"> <div class="title">Attribute-based Gesture Recognition: Generalization to Unseen Classes</div> <div class="author"> Georgios Retsinas,  <em>Panagiotis P. Filntisis</em>, Nikolaos Kardaris,  and Petros Maragos </div> <div class="periodical"> <em>In Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">retsinas2022attr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Attribute-based Gesture Recognition: Generalization to Unseen Classes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Retsinas, Georgios and Filntisis, Panagiotis P. and Kardaris, Nikolaos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div id="filntisis2021audiovisual" class="col-sm"> <div class="title">An Audiovisual Child Emotion Recognition System for Child-Robot Interaction Applications</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2021_FilntisisEtAl_AV-ChildEmotionRecognSystem-ChildRobotInteract_EUSIPCO.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/multimodal-emotion-recognition/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">filntisis2021audiovisual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Audiovisual Child Emotion Recognition System for Child-Robot Interaction Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Efthymiou, Niki and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{791--795}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="pikoulis2021leveraging" class="col-sm"> <div class="title">Leveraging semantic scene characteristics and multi-stream convolutional architectures in a contextual approach for video-based visual emotion recognition in the wild</div> <div class="author"> Ioannis Pikoulis,  <em>Panagiotis P. Filntisis</em>,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2021_PikoulisEtAl_VideoEmotionRecognInTheWild-SemanticMultiStreamContext_FG.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/GiannisPikoulis/FG2021-BoLD" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pikoulis2021leveraging</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Leveraging semantic scene characteristics and multi-stream convolutional architectures in a contextual approach for video-based visual emotion recognition in the wild}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pikoulis, Ioannis and Filntisis, Panagiotis P. and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{01--08}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="antoniadis2021exploiting" class="col-sm"> <div class="title">Exploiting emotional dependencies with graph convolutional networks for facial expression recognition</div> <div class="author"> Panagiotis Antoniadis,  <em>Panagiotis P. Filntisis</em>,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/2021_AntoniadisEtAl_Emotion-GCN-FacialExpressionRecogn_FG.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/PanosAntoniadis/emotion-gcn" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">antoniadis2021exploiting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploiting emotional dependencies with graph convolutional networks for facial expression recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Antoniadis, Panagiotis and Filntisis, Panagiotis P. and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="efthymiou2021robotic" class="col-sm"> <div class="title">A robotic edutainment framework for designing child-robot interaction scenarios</div> <div class="author"> Niki Efthymiou,  <em>Panagiotis P. Filntisis</em>, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In PErvasive Technologies Related to Assistive Environments Conference (PETRA)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.researchgate.net/profile/Niki-Efthymiou/publication/352860176_A_robotic_edutainment_framework_for_designing_child-robot_interaction_scenarios/links/6194d04861f0987720a5f090/A-robotic-edutainment-framework-for-designing-child-robot-interaction-scenarios.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">efthymiou2021robotic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A robotic edutainment framework for designing child-robot interaction scenarios}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Efthymiou, Niki and Filntisis, Panagiotis P. and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{PErvasive Technologies Related to Assistive Environments Conference (PETRA)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{160--166}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="antoniadis2021audiovisual" class="col-sm"> <div class="title">An audiovisual and contextual approach for categorical and continuous emotion recognition in-the-wild</div> <div class="author"> Panagiotis Antoniadis, Ioannis Pikoulis,  <em>Panagiotis P. Filntisis</em>,  and Petros Maragos </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops (CVPRW)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/PanosAntoniadis/NTUA-ABAW2021" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">antoniadis2021audiovisual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An audiovisual and contextual approach for categorical and continuous emotion recognition in-the-wild}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Antoniadis, Panagiotis and Pikoulis, Ioannis and Filntisis, Panagiotis P. and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops (CVPRW)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3645--3651}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="garoufis2021unsupervised" class="col-sm"> <div class="title">An Unsupervised Learning Approach for Detecting Relapses from Spontaneous Speech in Patients with Psychosis</div> <div class="author"> C Garoufis, A Zlatintsi, PP Filntisis, N Efthymiou, E Kalisperakis, V Garyfalli, T Karantinos, L Mantonakis, N Smyrnis,  and P Maragos </div> <div class="periodical"> <em>In IEEE EMBS International Conference on Biomedical and Health Informatics (BHI)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://cvsp.cs.ntua.gr/publications/confr/Garoufis+_BHI2021_UnsupervisedLearningRelapseDetection_Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">garoufis2021unsupervised</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Unsupervised Learning Approach for Detecting Relapses from Spontaneous Speech in Patients with Psychosis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garoufis, C and Zlatintsi, A and Filntisis, PP and Efthymiou, N and Kalisperakis, E and Garyfalli, V and Karantinos, T and Mantonakis, L and Smyrnis, N and Maragos, P}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE EMBS International Conference on Biomedical and Health Informatics (BHI)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--5}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="efthymiou2021visual" class="col-sm"> <div class="title">Visual Robotic Perception System with Incremental Learning for Child–Robot Interaction Scenarios</div> <div class="author"> Niki Efthymiou,  <em>Panagiotis P. Filntisis</em>, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>Technologies</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2021_EfthymiouEtAl_VisualRobotPerceptionSystem-ChildRobotInteract_Technologies.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">efthymiou2021visual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual Robotic Perception System with Incremental Learning for Child--Robot Interaction Scenarios}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Efthymiou, Niki and Filntisis, Panagiotis P. and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Technologies}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{86}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Multidisciplinary Digital Publishing Institute}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div id="filntisis2020emotion" class="col-sm"> <div class="title">Emotion understanding in videos through body, context, and visual-semantic embedding loss</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In European Conference on Computer Vision Workshops (ECCVW)</em> 2020 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/Emotion_understanding_in_videos_through_body__context__and_visual_semantic_embedding_loss-1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/NTUA-BEEU-eccv2020" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">filntisis2020emotion</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Emotion understanding in videos through body, context, and visual-semantic embedding loss}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Efthymiou, Niki and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision Workshops (ECCVW)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{747--755}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer, Cham}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Challenge Winner!}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="retsinas2020person" class="col-sm"> <div class="title">Person identification using deep convolutional neural networks on short-term signals from wearable sensors</div> <div class="author"> George Retsinas,  <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Emmanouil Theodosis, Athanasia Zlatintsi,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> 2020 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/icassp2020_retsinas.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">retsinas2020person</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Person identification using deep convolutional neural networks on short-term signals from wearable sensors}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Retsinas, George and Filntisis, Panagiotis P. and Efthymiou, Niki and Theodosis, Emmanouil and Zlatintsi, Athanasia and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3657--3661}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="maglogiannis2020intelligent" class="col-sm"> <div class="title">An intelligent cloud-based platform for effective monitoring of patients with psychotic disorders</div> <div class="author"> Ilias Maglogiannis, Athanasia Zlatintsi, Andreas Menychtas, Dennis Papadimatos,  <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, George Retsinas, Panayiotis Tsanakas,  and Petros Maragos </div> <div class="periodical"> <em>In IFIP International Conference on Artificial Intelligence Applications and Innovations</em> 2020 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2020_MaglogiannisEtAl_e-Prevention_IntelligentCloudPlatform_AIAI-1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maglogiannis2020intelligent</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An intelligent cloud-based platform for effective monitoring of patients with psychotic disorders}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maglogiannis, Ilias and Zlatintsi, Athanasia and Menychtas, Andreas and Papadimatos, Dennis and Filntisis, Panagiotis P. and Efthymiou, Niki and Retsinas, George and Tsanakas, Panayiotis and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IFIP International Conference on Artificial Intelligence Applications and Innovations}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{293--307}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer, Cham}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="filntisis2020identifying" class="col-sm"> <div class="title">Identifying differences in physical activity and autonomic function patterns between psychotic patients and controls over a long period of continuous monitoring using wearable sensors</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Athanasia Zlatintsi, Niki Efthymiou, Emmanouil Kalisperakis, Thomas Karantinos, Marina Lazaridi, Nikolaos Smyrnis,  and Petros Maragos </div> <div class="periodical"> <em>arXiv preprint arXiv:2011.02285</em> 2020 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2011.02285.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2020identifying</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Identifying differences in physical activity and autonomic function patterns between psychotic patients and controls over a long period of continuous monitoring using wearable sensors}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Zlatintsi, Athanasia and Efthymiou, Niki and Kalisperakis, Emmanouil and Karantinos, Thomas and Lazaridi, Marina and Smyrnis, Nikolaos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2011.02285}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div id="filntisis2019fusing" class="col-sm"> <div class="title">Fusing body posture with facial expressions for joint recognition of affect in child–robot interaction</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Petros Koutras, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em> 2019 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2019_FilntisisEtAl_FuseBodyFace-AffectRecogn-ChildRobotInteract_ieeeRAL.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/body-face-emotion-recognition" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2019fusing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fusing body posture with facial expressions for joint recognition of affect in child--robot interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Efthymiou, Niki and Koutras, Petros and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4011--4018}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="garoufis2019environment" class="col-sm"> <div class="title">An environment for gestural interaction with 3d virtual musical instruments as an educational tool</div> <div class="author"> Christos Garoufis, Athanasia Zlatintsi, Kosmas Kritsis,  <em>Panagiotis P. Filntisis</em>, Vassilis Katsouros,  and Petros Maragos </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> 2019 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/2019_GZKFKM_GestureInteractWithVirtualMusicInstrumentsForEducation_EUSIPCO-1-1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">garoufis2019environment</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An environment for gestural interaction with 3d virtual musical instruments as an educational tool}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garoufis, Christos and Zlatintsi, Athanasia and Kritsis, Kosmas and Filntisis, Panagiotis P. and Katsouros, Vassilis and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--5}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div id="tsiami2018far" class="col-sm"> <div class="title">Far-field audio-visual scene perception of multi-party human-robot interaction for children and adults</div> <div class="author"> Antigoni Tsiami,  <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Petros Koutras, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> 2018 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/publications/2018_TsiamiEtAl_FarfieldAVperceptionHRI-ChildrenAdults_ICASSP.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tsiami2018far</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Far-field audio-visual scene perception of multi-party human-robot interaction for children and adults}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tsiami, Antigoni and Filntisis, Panagiotis P. and Efthymiou, Niki and Koutras, Petros and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6568--6572}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="efthymiou2018multi" class="col-sm"> <div class="title">Multi-view fusion for action recognition in child-robot interaction</div> <div class="author"> Niki Efthymiou, Petros Koutras,  <em>Panagiotis P. Filntisis</em>, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> 2018 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/EfthymiouKoutrasFilntisis_MultiViewFusActRecognChildRobotInteract_ICIP18.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">efthymiou2018multi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-view fusion for action recognition in child-robot interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Efthymiou, Niki and Koutras, Petros and Filntisis, Panagiotis P. and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{455--459}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="tsiami2018multi3" class="col-sm"> <div class="title">Multi3: Multi-sensory perception system for multi-modal child interaction with multiple robots</div> <div class="author"> Antigoni Tsiami, Petros Koutras, Niki Efthymiou,  <em>Panagiotis P. Filntisis</em>, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em> 2018 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/publications/2018_TsiamiEtAl_Multi3-MultisensorMultimodalChildInteractMultRobots_ICRA.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tsiami2018multi3</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi3: Multi-sensory perception system for multi-modal child interaction with multiple robots}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tsiami, Antigoni and Koutras, Petros and Efthymiou, Niki and Filntisis, Panagiotis P. and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4585--4592}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="zlatintsi2018web" class="col-sm"> <div class="title">A web-based real-time kinect application for gestural interaction with virtual musical instruments</div> <div class="author"> Athanasia Zlatintsi,  <em>Panagiotis P. Filntisis</em>, Christos Garoufis, Antigoni Tsiami, Kosmas Kritsis, Maximos A Kaliakatsos-Papakostas, Aggelos Gkiokas, Vassilis Katsouros,  and Petros Maragos </div> <div class="periodical"> 2018 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/ZlatintsiEtAl_WebBasedRealTimeKinectAppGestInteractVMI_%CE%91%CE%9C18-1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">zlatintsi2018web</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A web-based real-time kinect application for gestural interaction with virtual musical instruments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zlatintsi, Athanasia and Filntisis, Panagiotis P. and Garoufis, Christos and Tsiami, Antigoni and Kritsis, Kosmas and Kaliakatsos-Papakostas, Maximos A and Gkiokas, Aggelos and Katsouros, Vassilis and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Audio Mostly 2018 on Sound in Immersion and Emotion}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--6}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div id="filntisis2017video" class="col-sm"> <div class="title">Video-realistic expressive audio-visual speech synthesis for the Greek language</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Athanasios Katsamanis, Pirros Tsiakoulis,  and Petros Maragos </div> <div class="periodical"> <em>Speech Communication</em> 2017 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/publications/FilntisisKatsamanisTsiakoulis+_VideoRealExprAudioVisSpeechSynthGrLang_SC17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/expressive-audiovisual-speech-synthesis-GR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2017video</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Video-realistic expressive audio-visual speech synthesis for the Greek language}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Katsamanis, Athanasios and Tsiakoulis, Pirros and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Speech Communication}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{95}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{137--152}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{North-Holland}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="filntisis2017photorealistic" class="col-sm"> <div class="title">Photorealistic adaptation and interpolation of facial expressions using HMMS and AAMS for audio-visual speech synthesis</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Athanasios Katsamanis,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> 2017 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.researchgate.net/profile/Panagiotis-Filntisis/publication/323352468_Photorealistic_adaptation_and_interpolation_of_facial_expressions_using_HMMS_and_AAMS_for_audio-visual_speech_synthesis/links/5aa9225baca272d39cd50414/Photorealistic-adaptation-and-interpolation-of-facial-expressions-using-HMMS-and-AAMS-for-audio-visual-speech-synthesis.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">filntisis2017photorealistic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Photorealistic adaptation and interpolation of facial expressions using HMMS and AAMS for audio-visual speech synthesis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Katsamanis, Athanasios and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2941--2945}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="filntisis2017demonstration" class="col-sm"> <div class="title">Demonstration of an HMM-based photorealistic expressive audio-visual speech synthesis system</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Athanasios Katsamanis,  and Petros Maragos </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> 2017 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.researchgate.net/profile/Panagiotis-Filntisis/publication/323354865_Demonstration_of_an_HMM-based_photorealistic_expressive_audio-visual_speech_synthesis_system/links/5aa922ab458515178818a351/Demonstration-of-an-HMM-based-photorealistic-expressive-audio-visual-speech-synthesis-system.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">filntisis2017demonstration</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Demonstration of an HMM-based photorealistic expressive audio-visual speech synthesis system}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Katsamanis, Athanasios and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4588--4588}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Panagiotis P. Filntisis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NFLPQH6TKP"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NFLPQH6TKP");</script> </body> </html>