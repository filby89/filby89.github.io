<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Panagiotis P. Filntisis</title> <meta name="author" content="Panagiotis P. Filntisis"/> <meta name="description" content=""/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://filby89.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/pfilntisis_cv.pdf">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Panagiotis P. Filntisis </h1> <p class="desc"><a href="https://robotics.ntua.gr/" target="_blank" rel="noopener noreferrer"><b>Intelligent Robotics and Automation Laboratory</b></a>, National Technical University of Athens</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile_acad-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile_acad-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile_acad-1400.webp"></source> <img src="/assets/img/profile_acad.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="profile_acad.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="social"> <div class="contact-note"> <a href="mailto:%66%69%6C%6E%74%69%73%69%73.%70%61%6E%61%67%69%6F%74%69%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=Z3Z8ipkAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/filby89" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/pfilntisis" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> </div> </div> </div> <div class="clearfix"> <p>I am a PostDoctoral researcher at the National Technical University of Athens under the supervision of <a href="https://robotics.ntua.gr/members/maragos/" target="_blank" rel="noopener noreferrer">Prof. Petros Maragos</a>. I am also a research associate at the <a href="https://www.athenarc.gr/en" target="_blank" rel="noopener noreferrer">Athena Research and Innovation Center</a>. I work at the crossroads of computer vision and audio processing for affective computing. Some of my most recent endeavors include <a href="https://arxiv.org/pdf/1901.01805.pdf" target="_blank" rel="noopener noreferrer"><b>body emotion recognition</b></a>, <a href="https://foivospar.github.io/NED/" target="_blank" rel="noopener noreferrer"><b>visual emotion translation</b></a>, and <a href="https://filby89.github.io/spectre/"><b>3D visual speech-aware facial expression reconstruction</b></a>.</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul 24, 2022</th> <td> Our latest preprint on using <b>lipreading</b> for improving 3D face reconstruction is <a href="https://filby89.github.io/spectre"><b>out</b></a>! </td> </tr> <tr> <th scope="row">Jun 24, 2022</th> <td> Our paper <a href="https://foivospar.github.io/NED/" target="_blank" rel="noopener noreferrer"><b>NED</b></a> was among the CVPR 2022 best paper finalists! </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/spectre.gif"></div> <div id="filntisis2022visual" class="col-sm-8"> <div class="title">Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, George Retsinas, Foivos Paraperas-Papantoniou, Athanasios Katsamanis, Anastasios Roussos,  and Petros Maragos </div> <div class="periodical"> <em>arXiv preprint arXiv:2207.11094</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2207.11094" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/spectre" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="https://filby89.github.io/spectre" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2022visual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Retsinas, George and Paraperas-Papantoniou, Foivos and Katsamanis, Athanasios and Roussos, Anastasios and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2207.11094}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ned.png"></div> <div id="paraperas2022ned" class="col-sm-8"> <div class="title">Neural Emotion Director: Speech-preserving semantic control of facial expressions in "in-the-wild" videos</div> <div class="author"> Foivos Paraperas Papantoniou,  <em>Panagiotis P. Filntisis</em>, Petros Maragos,  and Anastasios Roussos </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Oral - Best Paper Finalist)</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/Paraperas_NED-SpeechPreservingSemanticControlFacialExpressions_CVPR2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/foivospar/NED" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="https://foivospar.github.io/NED/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">paraperas2022ned</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Emotion Director: Speech-preserving semantic control of facial expressions in "in-the-wild" videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paraperas Papantoniou, Foivos and Filntisis, Panagiotis P. and Maragos, Petros and Roussos, Anastasios}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Oral - Best Paper Finalist)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/audiovisual.png"></div> <div id="filntisis2021audiovisual" class="col-sm-8"> <div class="title">An Audiovisual Child Emotion Recognition System for Child-Robot Interaction Applications</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2021_FilntisisEtAl_AV-ChildEmotionRecognSystem-ChildRobotInteract_EUSIPCO.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/multimodal-emotion-recognition/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">filntisis2021audiovisual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Audiovisual Child Emotion Recognition System for Child-Robot Interaction Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Efthymiou, Niki and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{791--795}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/beeu.png"></div> <div id="filntisis2020emotion" class="col-sm-8"> <div class="title">Emotion understanding in videos through body, context, and visual-semantic embedding loss</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>In European Conference on Computer Vision Workshops (ECCVW)</em> 2020 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/sites/2/Emotion_understanding_in_videos_through_body__context__and_visual_semantic_embedding_loss-1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/NTUA-BEEU-eccv2020" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">filntisis2020emotion</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Emotion understanding in videos through body, context, and visual-semantic embedding loss}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Efthymiou, Niki and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision Workshops (ECCVW)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{747--755}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer, Cham}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Challenge Winner!}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/fusing.png"></div> <div id="filntisis2019fusing" class="col-sm-8"> <div class="title">Fusing body posture with facial expressions for joint recognition of affect in child–robot interaction</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Niki Efthymiou, Petros Koutras, Gerasimos Potamianos,  and Petros Maragos </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em> 2019 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://robotics.ntua.gr/wp-content/uploads/sites/2/2019_FilntisisEtAl_FuseBodyFace-AffectRecogn-ChildRobotInteract_ieeeRAL.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/body-face-emotion-recognition" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2019fusing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fusing body posture with facial expressions for joint recognition of affect in child--robot interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Efthymiou, Niki and Koutras, Petros and Potamianos, Gerasimos and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4011--4018}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/eavtts.gif"></div> <div id="filntisis2017video" class="col-sm-8"> <div class="title">Video-realistic expressive audio-visual speech synthesis for the Greek language</div> <div class="author"> <em>Panagiotis P. Filntisis</em>, Athanasios Katsamanis, Pirros Tsiakoulis,  and Petros Maragos </div> <div class="periodical"> <em>Speech Communication</em> 2017 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://robotics.ntua.gr/wp-content/uploads/publications/FilntisisKatsamanisTsiakoulis+_VideoRealExprAudioVisSpeechSynthGrLang_SC17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/filby89/expressive-audiovisual-speech-synthesis-GR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2017video</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Video-realistic expressive audio-visual speech synthesis for the Greek language}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Katsamanis, Athanasios and Tsiakoulis, Pirros and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Speech Communication}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{95}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{137--152}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{North-Holland}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Panagiotis P. Filntisis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NFLPQH6TKP"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NFLPQH6TKP");</script> </body> </html>