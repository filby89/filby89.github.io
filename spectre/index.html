<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>SPECTRE - Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos | Panagiotis P. Filntisis</title> <meta name="author" content="Panagiotis P. Filntisis"/> <meta name="description" content="SPECTRE - Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>âš›</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://filby89.github.io/spectre/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://filby89.github.io/">Panagiotis P. Filntisis</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/pfilntisis_cv.pdf">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">SPECTRE - Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos</h1> </header> <article> <style type="text/css">.post-title{text-align:center;font-family:"Google Sans",sans-serif;color:#363636;font-size:2rem;font-weight:400;line-height:1.125}.publication-authors{margin-top:15px;text-align:center;font-family:"Google Sans",sans-serif}h3{font-family:"Google Sans",sans-serif;color:#363636;font-weight:400;line-height:1.125;text-align:center;margin-top:30px;margin-bottom:30px}.btn{padding:.5rem 1.5rem;text-transform:none;font-size:17px}.btn:hover{text-decoration:underline}.publication-icons{margin-top:30px;margin-bottom:30px}.abstract{text-align:justify}</style> <div class="publication-authors"> <span class="author-block"> <a href="https://filby89.github.io">Panagiotis P. Filntisis</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://georgeretsi.github.io" target="_blank" rel="noopener noreferrer">George Retsinas</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://scholar.google.com/citations?user=PngS31QAAAAJ" target="_blank" rel="noopener noreferrer">Foivos Paraperas-Papantoniou</a><sup>2</sup>, </span> <span class="author-block"> <a href="https://www.ilsp.gr/en/members/katsamanis-athanasios-nassos/" target="_blank" rel="noopener noreferrer">Athanasios Katsamanis</a><sup>3</sup>, </span> <span class="author-block"> <a href="https://users.ics.forth.gr/~troussos/" target="_blank" rel="noopener noreferrer">Anastassios Roussos</a><sup>4</sup>, </span> <span class="author-block"> <a href="https://robotics.ntua.gr/members/maragos/" target="_blank" rel="noopener noreferrer">Petros Maragos</a><sup>1</sup> </span> </div> <div class="row publication-icons"> <div class="col-sm" align="center"> <a class="btn btn-dark btn-rounded" href="https://arxiv.org/pdf/2207.11094" role="button" target="_blank" rel="noopener noreferrer"> <i class="fa fa-file-pdf"></i> Paper </a> <a class="btn btn-dark" href="https://arxiv.org/abs/2207.11094" role="button" target="_blank" rel="noopener noreferrer"> <i class="ai ai-arxiv"></i> arXiv </a> <a class="btn btn-dark btn-youtube" style="background-color: #ed302f; !important" href="https://youtu.be/P1kqrxWNizI" role="button" target="_blank" rel="noopener noreferrer"> <i class="fab fa-youtube"></i> Video </a> <a class="btn btn-dark" href="https://github.com/filby89/spectre" role="button" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> Code </a> </div> </div> <div class="alert alert-info"> <b>tl;dr:</b> we improve 3D facial reconstruction in videos by focusing on the lip formations and mouth movements, using a <b>lipreading</b> loss </div> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/cover2.drawio-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/cover2.drawio-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/cover2.drawio-1400.webp"></source> <img src="/assets/img/projects/cover2.drawio.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Cover image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Our method performs visual-speech aware 3D reconstruction so that speech perception from the original footage is preserved in the reconstructed talking head. On the left we include the word/phrase being said for each example. </div> <div class="row"> <div class="col-sm"> <h3>Teaser Video</h3> </div> </div> <div class="row justify-content-sm-center" align="center"> <div class="col-sm"> <iframe width="560" height="315" src="https://www.youtube.com/embed/P1kqrxWNizI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> </div> <div class="row"> <div class="col-sm"> <h3>Abstract</h3> </div> </div> <p class="abstract"> The recent state of the art on monocular 3D face reconstruction from image data has made some impressive advancements, thanks to the advent of Deep Learning. However, it has mostly focused on input coming from a single RGB image, overlooking the following important factors: a) Nowadays, the vast majority of facial image data of interest do not originate from single images but rather from videos, which contain rich dynamic information. b) Furthermore, these videos typically capture individuals in some form of verbal communication (public talks, teleconferences, audiovisual human-computer interactions, interviews, monologues/dialogues in movies, etc). When existing 3D face reconstruction methods are applied in such videos, the artifacts in the reconstruction of the shape and motion of the mouth area are often severe, since they do not match well with the speech audio. To overcome the aforementioned limitations, we present the first method for visual speech-aware perceptual reconstruction of 3D mouth expressions. We do this by proposing a "lipread" loss, which guides the fitting process so that the elicited perception from the 3D reconstructed talking head resembles that of the original video footage. We demonstrate that, interestingly, the lipread loss is better suited for 3D reconstruction of mouth movements compared to traditional landmark losses, and even direct 3D supervision. Furthermore, the devised method does not rely on any text transcriptions or corresponding audio, rendering it ideal for training in unlabeled datasets. We verify the efficiency of our method through exhaustive objective evaluations on three large-scale datasets, as well as subjective evaluation with two web-based user studies. </p> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col-sm"> <div class="bibtex"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">filntisis2022visual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Filntisis, Panagiotis P. and Retsinas, George and Paraperas-Papantoniou, Foivos and Katsamanis, Athanasios and Roussos, Anastasios and Maragos, Petros}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2207.11094}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 Panagiotis P. Filntisis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NFLPQH6TKP"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NFLPQH6TKP");</script> </body> </html>